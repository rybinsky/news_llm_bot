import os
import textwrap
from typing import Sequence

import streamlit as st
import torch
from dotenv import load_dotenv
from langchain.schema import StrOutputParser
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_huggingface import HuggingFaceEmbeddings as HFEmbedder
from langchain_ollama.llms import OllamaLLM

from bot.models import NewsArticle
from bot.services import EXAMPLES_CLS_TOPIC, DatabaseManager, TopicClassifier, load_config, setup_logging

torch.classes.__path__ = []

PROMPT = ChatPromptTemplate.from_template(
    textwrap.dedent(
        """
        –ü—Ä–µ–¥—Å—Ç–∞–≤—å —á—Ç–æ —Ç—ã —Å—Ç–µ–Ω–¥–∞–ø-–∫–æ–º–∏–∫ –∏ —Ç—ã –æ—á–µ–Ω—å —Å–º–µ—à–Ω–æ –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–µ—à—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏. –ó–∞ —Ö–æ—Ä–æ—à–∏–µ —à—É—Ç–∫–∏ —Ç–µ–±–µ –ø–ª–∞—Ç—è—Ç –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–∏–µ –¥–µ–Ω—å–≥–∏.
        –¢–≤–æ—è –∑–∞–¥–∞—á–∞ –ø—Ä–∏–¥—É–º–∞—Ç—å —Ö–æ—Ä–æ—à—É—é —à—É—Ç–∫—É, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ —Ç–µ–º–µ, –∫–æ—Ç–æ—Ä—É—é —è —Ç–µ–±–µ –¥–∞–º. –¢–≤–æ—è —à—É—Ç–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ç–æ–Ω–∫–æ–π –∏ –æ—Å—Ç—Ä–æ—É–º–Ω–æ–π.
        –®—É—Ç–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–º–µ—à–Ω–æ–π –∏ —Ç–æ–Ω–∫–æ–π –∏ –æ–ø–∏—Ä–∞—Ç—å—Å—è –Ω–∞ –¥–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç!

        –ö–æ–Ω—Ç–µ–∫—Å—Ç:
        {context}

        –¢–µ–º–∞: {question}

        –®—É—Ç–∫–∞:
    """
    )
)


def format_docs(docs: list[Document]) -> str:
    return "\n\n".join([d.page_content for d in docs])


def generate_response(
    llm: OllamaLLM, news: Sequence[NewsArticle], embedder: HFEmbedder, splitter: CharacterTextSplitter, query: str
) -> str:
    split_documents = splitter.create_documents([new.text for new in news])
    db = FAISS.from_documents(split_documents, embedder)
    retriever = db.as_retriever()
    chain = {"context": retriever | format_docs, "question": RunnablePassthrough()} | PROMPT | llm | StrOutputParser()
    return chain.invoke(query)


def main():
    """Main application entry point."""
    load_dotenv()
    st.title("ü§ñ AI-–∞–≥–µ–Ω—Ç: –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –º–µ–º–æ–≤ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º –Ω–æ–≤–æ—Å—Ç—è–º")
    st.markdown("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –Ω–∞ –ª—é–±–æ–º —è–∑—ã–∫–µ")

    config = load_config()

    logger = setup_logging(config.logging)

    text_embedder = HFEmbedder(
        model_name=config.text_embedder,
        model_kwargs={"device": torch.device("cuda" if torch.cuda.is_available() else "cpu")},
    )
    db_manager = DatabaseManager(logger)

    classifier = TopicClassifier(
        topics=set(config.classifier.topics),
        example_articles=EXAMPLES_CLS_TOPIC,
        model_name=config.ollama.model,
        temperature=config.classifier.temperature,
        max_attempts=config.classifier.max_attempts,
        logger=logger,
    )

    splitter = CharacterTextSplitter(
        separator="\n\n",
        chunk_size=500,
        chunk_overlap=100,
        length_function=len,
        is_separator_regex=False,
    )

    llm = OllamaLLM(model=config.generator.model, temperature=config.generator.temperature)

    try:
        db_manager.initialize(
            {
                "user": os.getenv("POSTGRES_USER"),
                "password": os.getenv("POSTGRES_PASS"),
                "host": os.getenv("POSTGRES_HOST"),
                "port": os.getenv("POSTGRES_PORT"),
                "database": os.getenv("POSTGRES_DB"),
            }
        )

        user_query = st.text_input("–û —á–µ–º –≤—ã —Ö–æ—Ç–∏—Ç–µ –º–µ–º/–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π?", "")

        if user_query:
            with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∏ –∏—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏..."):
                topic = classifier.classify(user_query)
                news = db_manager.get_last_news_by_topic(topic)
                response = generate_response(llm, news, text_embedder, splitter, user_query)

                st.subheader(f"–ß–∏—Ç–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Ç–µ–º–µ '{topic}'...")
                st.markdown("üí¨ **–ú–µ–º:**")
                st.write(response)

    except Exception as e:
        logger.error("Application error: %s", str(e), exc_info=True)

    finally:
        db_manager.close()


if __name__ == "__main__":
    main()
